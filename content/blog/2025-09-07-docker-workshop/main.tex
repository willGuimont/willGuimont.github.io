\documentclass[french]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[numbers]{natbib}
\usepackage{color,soul}
\usepackage{hyperref}
\usepackage{babel}
\usepackage{listings}
\lstset{
  basicstyle=\ttfamily,
  columns=fullflexible,
  frame=single,
  breaklines=true,
  postbreak=\mbox{\textcolor{red}{$\hookrightarrow$}\space},
}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
    pdftitle={GLO-2001 Workshops},
    pdfpagemode=FullScreen,
    }
\usepackage{geometry}
 \geometry{
 a4paper,
 total={170mm,257mm},
 left=20mm,
 top=20mm,
 }
\usepackage{comment}
\usepackage{tcolorbox}
\usepackage{siunitx}

% N.B. box
\newenvironment{notes}
{%
    \small
    \begin{tcolorbox}[boxrule=0.5pt, colback=white, colframe=black, arc=3mm]
    \par
    \noindent
    \underline{\textsc{\textbf{Note well:}}}
}
{%
    \end{tcolorbox}
}

% Exercises env
\newcounter{execounter}
\newcommand{\exeformat}[]{\num[minimum-integer-digits=2]{\theexecounter}}
\newcommand{\solscript}{Run the grading command \texttt{correction\_\exeformat.sh}\, to validate your answer.}
\newcommand{\soloutpath}{\texttt{$\sim$/out\_\exeformat.txt}}
\newcommand{\soloutscript}{Write your script's result to the file \soloutpath \>(with a redirection).}
\newenvironment{exercice}
{%
    \refstepcounter{execounter}
    \small
    \begin{tcolorbox}[boxrule=0.5pt, colback=white, colframe=black, arc=3mm]
    \par
    \noindent
    \underline{\textsc{\textbf{Exercise \theexecounter:}}}
}
{%
    \end{tcolorbox}
}

% To hide solutions, comment this line
\def\SOL{0}

\ifdefined\SOL
\newcounter{solcounter}
\newenvironment{solution}
{%
    \refstepcounter{solcounter}
    \small
    \begin{tcolorbox}[boxrule=0.5pt, colback=white, colframe=black, arc=3mm]
    \par
    \noindent
    \underline{\textsc{\textbf{Solution: \thesolcounter}}}
}
{%
    \end{tcolorbox}
}
\else
\excludecomment{solution}
\fi

% Listings
\lstset{basicstyle=\ttfamily,
  showstringspaces=false,
  commentstyle=\color{red},
  keywordstyle=\color{blue}
}

\title{Docker Workshop}
\author{IFT-2001: Operating Systems\\GLO-2001: Operating Systems for Engineering}
\date{}

\begin{document}

\maketitle

\section{Installation}

This workshop requires the use of a virtual machine, which you can download at this \href{https://ulavaldti-my.sharepoint.com/:u:/g/personal/masai45_ulaval_ca/Eblxxgdr3wRHqzPLtN5Kk8ABlj5v4ZDVMP3_A3IUaAc24A?e=OepHXl}{link}.
Once you have downloaded the VM, you can open it with \href{https://www.vmware.com/}{VMware} or \href{https://www.virtualbox.org/}{VirtualBox}.
To authenticate on the VM, use the username \texttt{glo2001} and the password \texttt{glo2001}.

Once authenticated, open a terminal with \texttt{CTRL-ALT-T} where you can run commands.
To verify that the VM works correctly, run the following command in the terminal:

\begin{lstlisting}[language=bash]
echo 'Hello world'
\end{lstlisting}

If everything is set up correctly, you should see \texttt{Hello world} printed to the console.
To enable clipboard sharing, change the option in \texttt{Devices -> Shared Clipboard -> Bidirectional}.

\section{Guidelines}

The provided VM is already configured correctly for the workshops.
Grading commands are of the form \texttt{correction\_nn}, where \texttt{nn} is an integer representing the exercise number, e.g., \texttt{correction\_03} for exercise 3.
Instructions to validate commands will be provided with the first question that has an expected result.

To complete this workshop, you must perform each exercise directly in the terminal.
You will use the \texttt{nano} text editor to modify the requested scripts.
To open a file with nano, run the following in the terminal.

\begin{lstlisting}[language=bash]
nano test.sh
\end{lstlisting}

You can then edit the file; enter

\begin{lstlisting}[language=bash]
echo 'Hello world'
\end{lstlisting}

To exit nano, press \texttt{CTRL-X}, then answer \texttt{y} to save the changes.
Run the following commands to validate that everything works:

\begin{lstlisting}[language=bash]
chmod +x test.sh
./test.sh
\end{lstlisting}

These commands should print \texttt{Hello world}.

\textbf{Adventurers only:} If you are comfortable with the command line, we encourage you to try completing this workshop using \texttt{vim} as your text editor.
A brief introduction to \texttt{vim} commands is available on \href{https://missing.csail.mit.edu/2020/editors/}{MIT's The Missing Semester}.
\texttt{vim} offers many shortcuts to edit text and code very efficiently.
As a programmer, you will spend a lot of time writing code, so investing in learning \texttt{vim} is worthwhile for the rest of your career.
There are plugins emulating \texttt{vim} commands for most IDEs: \href{https://marketplace.visualstudio.com/items?itemName=vscodevim.vim}{Vim for VS Code} or \href{https://plugins.jetbrains.com/plugin/164-ideavim}{IdeaVim for JetBrains products}.
\textbf{Please note that no assistance regarding \texttt{vim} will be provided during this workshop.}

\section{Solutions}
Proposed solutions to the exercises in these workshops are available in the following GitHub repository: \href{https://github.com/ulavalIFTGLOateliers/IFT2001-Docker}{ulavalIFTGLOateliers/IFT2001-Docker}.

\newpage
\section{Docker}

After your success with Bash, your manager has given you a new mission: find a solution to the application deployment problem.
Your company frequently encounters outages due to incompatibilities between different dependency versions.
Indeed, each developer can choose the operating system they wish to work on.
Consequently, some developers use different Linux distributions (Ubuntu, Arch, Gentoo), while others prefer Windows.

This situation often leads to version issues, as dependencies vary from one OS to another.
And worse, the versions used differ from those deployed on the production server.
The recurring excuse “It worked on my machine” when a developer causes a production outage has finally exasperated your manager. He is asking you to find a solution.

That’s how you discover Docker, a platform that lets you build, deploy, and run applications in lightweight, isolated containers.
With Docker, you can create a specific container for each microservice, including all required libraries and dependencies.
This approach ensures that each application will run consistently, regardless of library versions used by individual developers.
Moreover, Docker allows you to reproduce the development environment on the production server, thereby eliminating issues stemming from environment differences.

With Docker, you will tackle the challenge of running your company’s three main microservices.
Here are the microservices you must get working:

\begin{enumerate}
    \item a web server health monitoring application written in Haskell;
    \item a document management API written in Rust, requiring a PostgreSQL database; and
    \item a Python application for visualizing web server health.
\end{enumerate}

\subsection{Why containerization?}

\paragraph{Isolation}
One of the main advantages of containerization is isolation.
It often happens that different applications require specific dependency versions.
With Docker, you can install different dependency versions in distinct containers, without risking conflicts or compromising other applications.
Furthermore, if you need to run applications on different operating systems, such as Ubuntu and Arch Linux, you can simply wrap them in Docker containers, avoiding the need to rewrite applications for each system.

\paragraph{Portability}
Portability is another key advantage of Docker.
Once you have set up a development environment with all required dependencies, reproducing that configuration on other machines or for new team members becomes tedious.
Thanks to Docker, you can create an image that contains all required dependencies and configuration, which can be easily distributed and run on different platforms, whether Linux, Windows, or others.
This enables a new team member to start quickly without spending weeks configuring their environment.
It’s also an advantage when deploying applications to a server.

\paragraph{Reproducibility}
Reproducibility is also simplified with Docker.
Docker images are versioned, which means it is easy to reproduce builds identically, ensuring that development, test, and production environments are consistent.
You just need to specify the version of the Docker image used to guarantee consistency and avoid issues related to variations across environments.

\paragraph{Efficiency}
In terms of efficiency, Docker offers a significant advantage over virtual machines (VMs).
Unlike VMs, Docker does not need to run a full operating system for each container, which greatly reduces resource consumption.
Docker containers share the host kernel, making them lightweight and quick to start.

\paragraph{Community}
Docker’s surrounding community is very active and offers a multitude of preconfigured images for various popular tools and technologies such as Node.js, Python, and many others.
These preconfigured images facilitate deployment and usage of these technologies, saving developers time by avoiding manual environment setup.

\paragraph{Industry}
Finally, it’s important to emphasize that Docker has become a de facto standard in the software development industry.
Many companies use Docker for development, testing, and deployment of their applications.
Docker is now an essential tool for software developers.

\subsection{What is containerization?}

Docker is an open-source software platform that lets you create, deploy, and run applications in lightweight, isolated containers.
A Docker container is a runtime unit that encapsulates an application together with all of its necessary elements, such as libraries, dependencies, and configuration files.
These containers are self-contained and portable, meaning they can run consistently across different systems, whether a development, test, or production environment.

Docker is similar to a virtual machine that isolates an application from the host system.
However, Docker is much more efficient than a VM, which requires a full operating system for each instance.
Docker instead shares the host operating system’s \texttt{kernel}, saving resources and making containers faster to start and run.

Here is some Docker terminology.
You do not have to read the advanced sections to complete this workshop.
As a supplement, you can watch the video \href{https://www.youtube.com/watch?v=J0NuOlA2xDc}{“Never install locally”}\cite{coderized2023docker}.

\paragraph{Docker Image}
A Docker image is a template or build blueprint that contains all the elements needed to run an application.
It includes the operating system, libraries, dependencies, the application’s source code, and configuration files.
Docker images are created from files called \texttt{Dockerfile} that specify the steps to build the image.

\paragraph{Dockerfile}
A Dockerfile is a text file that contains the instructions to build a Docker image.
It specifies the image layers, dependencies to install, files to include, and commands to run during image construction.

\paragraph{Docker Container}
A Docker container is a running instance of a Docker image.
It is an isolated environment that runs the application with its dependencies.
Containers are lightweight, portable, and self-contained, which makes them easy to deploy across different machines.

\paragraph{Docker Registry}
A Docker registry is a centralized repository that stores and manages Docker images.
The default public registry is \href{https://hub.docker.com/}{Docker Hub}, where you can find many ready-to-use images.
You can also create and use your own private registry to store your own images.

\paragraph{\textit{Union filesystem} (advanced)}
The \textit{Union Filesystem}, also known as \textit{UnionFS} or \textit{OverlayFS}, is a technology used by Docker to manage images and container layers efficiently.
The \textit{Union Filesystem} allows you to overlay multiple file systems into a single logical view without physically merging them.
This means Docker images and containers can share and reuse common file layers, saving storage space.
It also speeds up image builds by caching layers already built.
When a container starts, a new read-write layer is added on top of the image layers, enabling container-specific changes without affecting others.

\paragraph{\textit{cgroups} (advanced)}
\textit{cgroups}, or \textit{control groups}, are a Linux kernel feature used by Docker to limit and manage system resources used by containers.
\textit{cgroups} allow control of resources such as CPU, memory, disk bandwidth, and network, ensuring balanced and fair resource usage among containers.
Docker uses \textit{cgroups} to set limits and quotas on resources allocated to each container, ensuring isolation and predictable performance.

\paragraph{\textit{Namespaces} (advanced)}
Namespaces are a Linux kernel feature that isolates system resources among processes.
Docker uses several types of namespaces to provide isolation between containers, including the PID namespace (process isolation), the network namespace (network isolation), the user namespace (user isolation), and the mount namespace (mount point isolation).
These namespaces ensure that each container has its own isolated view of the system, preventing processes in one container from interfering with others or with the host system.

\paragraph{\textit{Chroot jail} (advanced)}
Chroot, or change root, is a Unix/Linux feature that changes a process’s root directory and limits its access to the file system.
Docker uses chroot to create an isolated environment inside the container, where the container’s root directory becomes the starting point for all file paths.
This limits the container’s access to files and directories outside its isolated environment, thereby strengthening security and isolation.

\subsection{Containers manually}

To clearly illustrate what Docker does, we will manually build a simplified container without using Docker.
This section is inspired by \cite{rajpurohit2023docker}.
In a terminal, enter the following commands:

\begin{lstlisting}[language=bash]
# Verify that neofetch is not installed
# The following command should raise an error; do not install the package
neofetch

# Folder for containers
mkdir ~/containers; cd ~/containers

# Build the container's filesystem
sudo apt update; sudo apt install -y debootstrap
sudo debootstrap jammy ./ubuntu-container http://archive.ubuntu.com/ubuntu/

# Create an isolated environment (namespace)
sudo unshare --uts --pid --mount --ipc --fork

# Mount process, system, device, and temp folders
mount -t proc none ./ubuntu-container/proc/
mount -t sysfs none ./ubuntu-container/sys
mount -o bind /dev ./ubuntu-container/dev
mount -o bind /tmp ./ubuntu-container/tmp/
cp /etc/apt/sources.list ./ubuntu-container/etc/apt/sources.list

# Use chroot to launch a shell in the container
chroot ./ubuntu-container/ /bin/bash
# and there you go, you're in an isolated container

# Install neofetch
apt update
apt install -y neofetch

# Test neofetch; the command works!
neofetch

# You can run commands in the container here.

# Exit the container
exit

# Exit unshare
exit

# If we try neofetch again, the command is not found.
# We have indeed isolated the container!
neofetch
\end{lstlisting}

As you can see, there is no magic in containers.
We use basic Linux tools to isolate a process in its own filesystem.
Here is another interesting resource on Docker internals: \href{https://github.com/p8952/bocker}{p8952/bocker: Docker implemented in around 100 lines of bash}.

\subsection{Docker basics}

\begin{exercice}
    Running a prebuilt image\\

    Run the Docker image \texttt{hello-world}.
    
    \begin{notes}
        To run a Docker image, use the \texttt{run} command.
    
        \begin{lstlisting}[language=bash]
docker run image-name
        \end{lstlisting}
    \end{notes}

    If the command works, you will see a message displayed.
\end{exercice}

\begin{solution}
    \begin{lstlisting}[language=bash]
docker run hello-world
    \end{lstlisting}
\end{solution}

\begin{notes}
    To execute a command in the container, specify the command at the end of \texttt{run}.
    In the following examples, we pass \texttt{bash -c 'echo "Hello world"'} which interprets the string in the Bash interpreter.
    
    \begin{lstlisting}[language=bash]
# Prints 'Hello world' in an ubuntu container
docker run ubuntu bash -c 'echo "Hello world"'
# Prints information about the host system
cat /etc/os-release
# Prints information from a container running Arch Linux
docker run archlinux bash -c 'cat /etc/os-release'
    \end{lstlisting}
\end{notes}

\begin{notes}
    To launch an interactive command (such as a shell), use the \texttt{-it} flag.
    The \texttt{--rm} flag removes the container once it exits.
    \begin{lstlisting}[language=bash]
docker run -it --rm archlinux bash
    \end{lstlisting}
\end{notes}

\begin{exercice}
    Container management\\

    \begin{notes}
        To see running containers: \texttt{docker ps}.

        To stop a container: \texttt{docker stop container\_id}.

        \textbf{Note that the command may take some time to run.}
    \end{notes}

    \begin{itemize}
        \item Launch an interactive terminal with Docker;
        \item Open another terminal and inspect running containers;
        \item Stop the Docker container from the second terminal.
    \end{itemize}

\end{exercice}

\begin{solution}
    \begin{lstlisting}[language=bash]
# In the first terminal
docker run -it archlinux bash

# In the second terminal
docker ps
docker stop id
# or
docker rm -f id
    \end{lstlisting}
\end{solution}

\begin{notes}
    To set environment variables in a container, use the \texttt{-e} flag.

    \begin{lstlisting}[language=bash]
docker run -it --rm -e HELLO=hello archlinux sh -c 'echo $HELLO'
    \end{lstlisting}
\end{notes}

\begin{notes}
    To open a network port, use the \texttt{-p docker:host} flag, where \texttt{docker} is the port number inside the container and \texttt{host} is the port number on the host.
    
    \begin{lstlisting}[language=bash]
docker run -p 127.0.0.1:8080:80 nginx
# You can access the port via the URL http://localhost:8080/
curl http://localhost:8080/
    \end{lstlisting}
\end{notes}

\begin{exercice}
    Launch a PostgreSQL database with Docker.

    \begin{itemize}
        \item The image name is \texttt{postgres};
        \item Set the environment variable \texttt{POSTGRES\_PASSWORD=postgres}; and
        \item Map Docker port 5432 to host port 5432;
        \item Leave this container running.
    \end{itemize}
    
\end{exercice}

\begin{solution}
    \begin{lstlisting}[language=bash]
docker run -e POSTGRES_PASSWORD=postgres -p 5432:5432 --rm postgres
# or
docker run --name postgres -e POSTGRES_PASSWORD=postgres -p 5432:5432 --rm -d postgres
    \end{lstlisting}
\end{solution}

\subsection{Dockerfile}
Dockerfiles are configuration files used to create custom Docker images.
They allow you to define, reproducibly and automatically, an application's runtime environment inside a Docker container.

A Dockerfile contains a series of instructions that specify the steps needed to build a Docker image.
These instructions include actions such as selecting the base image, installing dependencies, configuring environment variables, copying files, running commands, and more.

Here is an annotated example Dockerfile for a Python application.

\begin{lstlisting}
# Use the Python 3.9 slim base image
FROM python:3.9-slim

# Set the working directory inside the container
# Specifies the directory for RUN, CMD, ENTRYPOINT, COPY, and ADD
WORKDIR /app

# Copy requirements.txt from the host into the Docker container
COPY requirements.txt .

# Run a Bash command to install Python dependencies
RUN pip install -r requirements.txt

# Copy the source code into the Docker container
COPY . .

# Set the default command when the container starts
CMD ["python", "app.py"]
\end{lstlisting}

To build the image, use \texttt{docker build -t <tag> .}.
The \texttt{-t <tag>} argument gives the image the name \texttt{<tag>}.
For the previous application, you could use “\texttt{docker build -t python-app .}”.
Note that the order of instructions matters.

It is crucial to define the order of operations in a Dockerfile due to how Docker builds images.
Each instruction in the Dockerfile creates a new layer in the Docker image, and the order can significantly impact build efficiency and performance.

Docker uses a cache to speed up image builds.
When you run an instruction, Docker checks whether that instruction has already been executed in a previous layer.
If so and the parameters are identical, Docker reuses the cached layer instead of rebuilding it.
This saves build time.
However, if you modify an instruction higher up in the Dockerfile, all subsequent instructions will have their cache invalidated and must be rebuilt.
For example, if you perform resource-intensive operations such as compiling code that changes whenever you modify the source, it can be preferable to place those steps towards the end of the Dockerfile to benefit from caching as much as possible.

\begin{exercice}
    Use the \texttt{README.md} in the folder \texttt{$\sim$/Applications/status-checker} to write a Dockerfile that runs the Haskell application.\\

    Your Dockerfile must:
    \begin{itemize}
        \item Use the base image \texttt{haskell:9.0-buster};
        \item Run \texttt{stack setup -{}-install-ghc};
        \item Choose \texttt{/app} as the workdir;
        \item Copy the source code into the container’s \texttt{/app} folder;
        \item Run \texttt{stack build};
        \item Launch the server with \texttt{stack run}.
    \end{itemize}\\

    Then, start the container exposing port 8080.
    If everything works, you should be able to run the following request:

    \begin{lstlisting}[language=bash]
curl http://localhost:8080/endpoints
# Expected response
{}%
# Or
{}
    \end{lstlisting}
    
    Leave this container running.
\end{exercice}

\begin{solution}
    Dockerfile:
    \begin{lstlisting}
FROM haskell:9.0-buster
RUN stack setup --install-ghc
WORKDIR /app
COPY . .
RUN stack build
CMD ["stack", "run"]
    \end{lstlisting}
    Execution:
    \begin{lstlisting}[language=bash]
docker build -t status-checker .
docker run --rm -p 8080:8080 status-checker
    \end{lstlisting}
\end{solution}

\begin{exercice}
    Use the \texttt{README.md} in the folder \texttt{$\sim$/Applications/python\_app} to write a Dockerfile that runs the Python application.

    Then, launch the application interactively and with the correct network mode.

    \begin{notes}
        This application will need to access your computer’s local network to make requests to the container from the previous exercise; to do so, pass the argument \texttt{-{}-network="host"} when you run the container.
    \end{notes}

    If everything works, you should be able to use the application to add URLs to monitor and see the results.
\end{exercice}

\begin{solution}
    Dockerfile:
    \begin{lstlisting}
FROM python:3.9-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
CMD ["python", "main.py"]
    \end{lstlisting}
    Execution:
    \begin{lstlisting}[language=bash]
docker build -t python_app .
docker run --rm -it --network="host" python_app
    \end{lstlisting}
\end{solution}

\subsection{Advanced Docker}

\subsubsection{\textit{Multi-stage image builds}}

Multi-stage builds are an advanced Docker feature that enables optimized image creation using several distinct stages in the build process.
This separates build and production stages, often resulting in final images that are lighter and more secure by minimizing what remains in the final image.

For example, for a JavaScript React application, we can split the build into two stages.

Create the application:

\begin{lstlisting}[language=bash]
npx create-react-app my-app
\end{lstlisting}

Dockerfile:

\begin{lstlisting}
# Stage 1: Build the application

# Use `as build` to name this build stage
FROM node:14-alpine as build
WORKDIR /app
COPY package*.json ./
RUN npm install
COPY . .
RUN npm run build

# Stage 2: Prepare the server
# Here, we start a new image from scratch
FROM nginx:alpine
# Copy the compiled app from the previous stage
COPY --from=build /app/build /usr/share/nginx/html
EXPOSE 80
CMD ["nginx", "-g", "daemon off;"]
\end{lstlisting}

To run:

\begin{lstlisting}[language=bash]
docker build -t web-app .
docker run --rm -p 80:80 web-app
\end{lstlisting}

\begin{exercice}
    Use the \texttt{README.md} in the folder \texttt{$\sim$/Applications/rust\_api} to write a Dockerfile that runs the application.

    \begin{itemize}
        \item Launch the PostgreSQL database from a previous exercise;
        \item Create a first stage to compile the Rust code;
        \item Create a second stage to run the code;
        \begin{itemize}
            \item Start this image from \texttt{debian:bullseye-slim};
            \item Install the package \texttt{libpq-dev} with \texttt{apt update; apt install -y libpq-dev};
            \item Set the environment variable \texttt{DATABASE\_URL=postgres://postgres:postgres@localhost}
            \item Copy \texttt{/app/target/release/rust\_api} from the previous stage;
        \end{itemize}
        \item Run the container with \texttt{-{}-network="host"} and expose the correct port;
        \item Test that everything works with \texttt{curl http://localhost:8081/documents}.
    \end{itemize}

\end{exercice}

\begin{solution}
    \begin{lstlisting}
FROM rust:latest AS build
WORKDIR /app
COPY . .
RUN cargo build --release

FROM debian:bullseye-slim
RUN apt update; apt install -y libpq-dev
WORKDIR /app
COPY --from=build /app/target/release/rust_api ./rust_api
ENV DATABASE_URL=postgres://postgres:postgres@db
CMD ./rust_api
    \end{lstlisting}
    Execution
    \begin{lstlisting}
docker run -e POSTGRES_PASSWORD=postgres -p 5432:5432 postgres
docker build -t rust_api .
docker run --rm --network="host" rust_api

# Validate that the server works
curl http://localhost:8081/documents
    \end{lstlisting}
\end{solution}

\subsubsection{Volumes}

In Docker, volumes are used to allow containers to access, share, and persist data between the host system and the container itself.
Docker volumes store data outside the lifecycle of containers.
This means that even if you destroy or recreate a container, the data stored in the volume remains intact.
This separates data persistence from the container environment, providing better data management.
Volumes are also useful to grant containers access to datasets too large to copy into the image, such as a training dataset for a machine learning system.

For example, to store PostgreSQL database data in a host folder, specify the \texttt{PGDATA} variable and mount a volume:

\begin{lstlisting}[language=bash]
docker run -e POSTGRES\_PASSWORD=postgres -p 5432:5432 --rm \
    -e PGDATA=/var/lib/postgresql/data/pgdata \
    -v custom/mount/path:/var/lib/postgresql/data \
    postgres
\end{lstlisting}

To avoid rebuilding the Docker image after each change to the source code—and thus speed up development—you can make the project’s source code accessible via a volume.
Thus, a \texttt{DockerfileDev} for the Python application could look like this:

\begin{lstlisting}
FROM python:3.9-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
# We removed the line COPY . .
CMD ["bash"]
\end{lstlisting}

Run with:
\begin{lstlisting}[language=bash]
docker build -t python_app -f DockerfileDev . 
docker run --rm -v .:/app my-app
# In the container
python main.py
# Modify the source code
python main.py
# Changes are reflected in the container
\end{lstlisting}

Thus, you can reuse the same image even if the source code has changed.

\subsection{Extras}

\subsubsection{Cleanup}

When using Docker, it is important to consider the storage used by images, containers, volumes, and other Docker artifacts.
Poor storage management can lead to excessive disk usage and make Docker maintenance and resource management difficult.
Docker provides several \texttt{prune} commands to remove unused containers and images.
To clean up various Docker artifacts, the command \texttt{docker system prune -a -f} removes all unused resources.

\subsubsection{Docker Compose}

Docker Compose is a tool that allows you to easily define and manage multi-container applications.
It simplifies deployment and orchestration of Docker containers using a simple, readable configuration file.

With Docker Compose, you can specify services, networks, volumes, and other configurations needed to run an application composed of multiple containers.
You can also define dependencies among containers, environment variables, exposed ports, etc.

Docker Compose uses a YAML configuration file to describe the application’s infrastructure.
This file contains sections such as \textit{services}, \textit{networks}, \textit{volumes}, etc., where you can define the different parts of your application and their configurations.

Here is an example \texttt{docker-compose.yml} for the Rust application that launches both the server and the PostgreSQL database:

\begin{lstlisting}
# List of containers to launch
services:
  # Database container
  # We find the same parameters as in `docker run`
  db:
    # Specify the image to launch
    image: postgres:latest
    restart: always
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - PGDATA=/var/lib/postgresql/data/pgdata
    expose:
      - 5432
    volumes:
      - db:/var/lib/postgresql/data
  # Rust server
  api:
    # Will build the Dockerfile in the directory containing docker-compose.yml
    build: .
    # Build the db service before api
    depends_on:
      - db
    ports:
      - 8081:8081
    # The database URL changes—rather than @localhost
    # docker-compose makes db accessible under the name @db
    environment:
      - DATABASE_URL=postgres://postgres:postgres@db
    # Wait for the database to be ready before launching the server
    entrypoint: bash -c "sleep 5 && ./rust_api"
# Required for the database volume
volumes:
  db:
    driver: local
\end{lstlisting}

And you can run it with:

\begin{lstlisting}
docker-compose up --build
\end{lstlisting}

\subsubsection{Podman}

\href{https://podman.io/}{Podman} is an open-source alternative to Docker.
Docker and Podman are two popular containerization tools that share similar features but differ in architecture and security approach.
Docker uses a client-server architecture, where the Docker daemon runs as a separate process and Docker commands are executed via the CLI.
In contrast, Podman uses a daemonless architecture, meaning it runs directly as a regular user and does not require a separate daemon process.
Thus, Podman can run without special privileges, limiting potential risks associated with running as superuser. \cite{redhat2022podman}

Podman also offers tools to manage \textit{pods}, a topic outside the scope of this workshop.

\subsubsection{Kubernetes}

Kubernetes is an open-source container orchestration system that facilitates the deployment, management, and scaling of containerized applications.
Using Kubernetes offers many benefits, such as fault tolerance, easier deployments, and management and scaling of containerized applications.

\newpage
\nocite{*}
\bibliographystyle{plainnat}
\bibliography{citations}

\end{document}
